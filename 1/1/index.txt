3:I[4707,[],""]
6:I[6423,[],""]
7:I[2798,["185","static/chunks/app/layout-c0991f7d76273a13.js"],"ThemeProvider"]
8:I[9734,["185","static/chunks/app/layout-c0991f7d76273a13.js"],"DynamicFavicon"]
9:I[8291,["185","static/chunks/app/layout-c0991f7d76273a13.js"],"Analytics"]
4:["month","1","d"]
5:["day","1","d"]
0:["VQoYmXv-G56ZgJRRzJJFi",[[["",{"children":[["month","1","d"],{"children":[["day","1","d"],{"children":["__PAGE__?{\"month\":\"1\",\"day\":\"1\"}",{}]}]}]},"$undefined","$undefined",true],["",{"children":[["month","1","d"],{"children":[["day","1","d"],{"children":["__PAGE__",{},[["$L1","$L2",null],null],null]},[null,["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children","$5","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}]],null]},[null,["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}]],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/2025/_next/static/css/df8c932e539912be.css","precedence":"next","crossOrigin":"$undefined"}]],["$","html",null,{"lang":"en","suppressHydrationWarning":true,"className":"h-full","children":["$","body",null,{"className":"min-h-full bg-white dark:bg-black","children":[["$","$L7",null,{"children":["$","div",null,{"className":"flex flex-col min-h-full","children":[["$","$L8",null,{}],["$","div",null,{"className":"flex-1 w-full","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]}],["$","footer",null,{"className":"text-center text-sm text-gray-600 dark:text-gray-400 py-4 bg-white dark:bg-black","children":["© ",2025," Michael Pilosov. All rights reserved."]}]]}]}],["$","$L9",null,{}]]}]}]],null],null],["$La",null]]]]
b:I[2972,["450","static/chunks/450-fc8431448c3438bc.js","878","static/chunks/878-5d3156bd3161bc5d.js","160","static/chunks/app/%5Bmonth%5D/%5Bday%5D/page-475f15d3cd396c50.js"],""]
c:I[1190,["450","static/chunks/450-fc8431448c3438bc.js","878","static/chunks/878-5d3156bd3161bc5d.js","160","static/chunks/app/%5Bmonth%5D/%5Bday%5D/page-475f15d3cd396c50.js"],"ThemeToggle"]
d:I[5878,["450","static/chunks/450-fc8431448c3438bc.js","878","static/chunks/878-5d3156bd3161bc5d.js","160","static/chunks/app/%5Bmonth%5D/%5Bday%5D/page-475f15d3cd396c50.js"],"Image"]
2:["$","div",null,{"className":"min-h-screen bg-white dark:bg-black text-black dark:text-white","children":[["$","header",null,{"className":"flex justify-between items-center mb-8 px-4","children":[["$","$Lb",null,{"href":"/","className":"text-2xl font-bold hover:underline","children":"2025 (12 Events)"}],["$","div",null,{"className":"flex items-center","children":[["$","$Lb",null,{"href":"/about","className":"hover:underline mr-4","children":"About"}],["$","$Lc",null,{}]]}]]}],["$","nav",null,{"className":"flex justify-between w-full mb-8 text-3xl font-bold text-gray-600 dark:text-gray-400 px-4","children":[["$","div",null,{"className":"flex-1 flex justify-start","children":null}],["$","div",null,{"className":"flex-1 flex justify-end","children":["$","$Lb",null,{"href":"/1/2","className":"hover:underline","children":"→"}]}]]}],["$","main",null,{"children":["$","div",null,{"className":"max-w-content mx-auto px-4","children":["$","article",null,{"children":[["$","h1",null,{"className":"text-3xl font-bold mb-2","children":"Initial Experiments in Image Understanding"}],["$","p",null,{"className":"text-gray-600 dark:text-gray-400 mb-4","children":"2025-01-01"}],["$","div",null,{"className":"prose dark:prose-invert mb-8 [&>p]:mb-4 [&_a]:underline [&_a:hover]:text-gray-600 dark:[&_a:hover]:text-gray-300 [&>ul]:list-disc [&>ul]:pl-6 [&>ul]:mb-4 [&>ul>li]:pl-2","children":[["$","h2","0",{"children":"Context"}],"\n",["$","p","2",{"children":"I have long been interested in how machines perceive the world.\nWe are told so much about “artificial intelligence” and are impressed by new capabilities, but I have always had my reservations and suspicions that there was more pattern-matching going on, and less understanding."}],"\n",["$","p","4",{"children":"Speculations on whether the current architectures will end up being the path forward is not in scope for this first post."}],"\n",["$","p","6",{"children":"One thing is for certain: the capabilities demonstrated by language models in 2024 were incredible leaps forward.\nThe resources required for leveraging these best-performing models are prohibitive, but I have explored the functionality of open / permissive models, and thought a lot about how to incorporate them into my artistic practice."}],"\n",["$","p","8",{"children":["To date, I have not finalized any projects that leveraged language models, but I have been studying the relationship between what Machine Learning models “learn” and consequently how they perceive / interpret the world.\nOne of my prior ",["$","a","1",{"href":"https://hues.mpilosov.com","children":"projects"}]," interrogated this question through the lens of arranging colors."]}],"\n",["$","p","10",{"children":"This year, I want to actualize my experiments with language models, and turn some sketches of ideas into something visually compelling that I can print or animate."}],"\n",["$","h2","12",{"children":"A Model of Interest"}],"\n",["$","p","14",{"children":["Recently I came across ",["$","a","1",{"href":"https://arxiv.org/abs/2306.14824","children":"Kosmos-2"}],", a “Multimodal Large Language Model (MLLM)” that enables new capabilities of perceiving object descriptions (e.g., bounding boxes) and “grounding text” to the visual world."]}],"\n",["$","p","16",{"children":"What the authors mean by “grounding text” is that the model can answer questions about the image and cite its answers as part of its response in a structured format.\nIn essence, this is the textual equivalent of a computer “pointing” to things in a picture, citing its answers."}],"\n",["$","p","18",{"children":"Models that draw bounding boxes and recognize objects in images have long existed, as have models that can provide a description (caption) of an image.\nWhat makes this one different is that it is providing both at the same time, using the transformer architecture which has led to the recent AI / LLM developments in the headlines."}],"\n",["$","p","20",{"children":"This model (unlike those that caption images), allows for free-form questions, meaning they can be explored and interacted with through “prompt engineering.”"}],"\n",["$","h2","22",{"children":"Artistic Inspiration"}],"\n",["$","p","24",{"children":"This model appeals to me for a few potential use cases.\nI like that it can answer questions about the world and ground responses in object detections."}],"\n",["$","p","26",{"children":"I can imagine a system that watches the world and tries to explain it in real-time, while we humans watch its understanding of the world evolve in real-time through some visualization technique."}],"\n",["$","p","28",{"children":"I want to see what this model thinks is in the photographs I take."}],"\n",["$","p","30",{"children":"Moreover, I am interested in having conversations with this model about the compositions and aesthetics of my abstract art, a task which was surely outside the scope of its training regiment, but one that I can hopefully hack together."}],"\n",["$","h2","32",{"children":"First Steps"}],"\n",["$","p","34",{"children":"I needed to download the model from HuggingFace, following the documentation in Microsoft’s github repository.\nIt was pretty easy to get inference working, and after going through a handful of their examples, I was ready to start using my own images and began refactoring the inference code for distributed compute."}],"\n",["$","p","36",{"children":"One thing I do often is split video into still-frames, process them, and stitch them back together.\nGiven that this model takes an image as input, this workflow seemed quite appropriate to try."}],"\n",["$","h2","38",{"children":"Early Trials"}],"\n",["$","p","40",{"children":"First, here is a ~30s video clip I took on my phone while visiting an aquarium."}],"\n",["$","p","42",{"children":"\n"}],["$","figure","43",{"children":["\n        ",["$","video","1",{"controls":true,"children":["\n          ",["$","source","1",{"src":"https://cdn.math.computer/v/kosmos2/fish/sm/input.mp4","type":"video/mp4","children":"$undefined"}],"\n          Your browser does not support the video tag.\n        "]}],"\n        ",["$","figcaption","3",{"className":"text-center text-sm text-gray-600 dark:text-gray-400","children":"Original video, taken at Seattle Aquarium, Dec 2024. Scaled to 1/3 resolution."}],"\n      "]}],["$","p","44",{"children":"$undefined"}],"\n",["$","p","46",{"children":"I absolutely fell in love watching this fish tunnel a home for itself underneath a coral."}],"\n",["$","p","48",{"children":"For some reason, this clip came to mind as something interesting to run through the model."}],"\n",["$","ul","50",{"children":["\n",["$","li","1",{"children":["There’s a diversity of things going on but not ",["$","em","1",{"children":"too"}]," much."]}],"\n",["$","li","3",{"children":"It should be clearly recognizable as an aquarium, which should ground the context of answers to some degree (for example, it would be reasonable to misidentify a fish for an eel but not a dog)"}],"\n",["$","li","5",{"children":"There are varying levels of zoom, which changes the frame of what is visible in the scene."}],"\n",["$","li","7",{"children":"Something “interesting” is happening in it - but the behavior is observed over time. Trying to identify it from any given frame would be challenging."}],"\n",["$","li","9",{"children":"It’s calming to look at, which is important for me during testing algorithms since I’ll be reviewing the footage a lot."}],"\n"]}],"\n",["$","p","52",{"children":"I first tried a generic “Describe this scene:” prompt, but on individual frames I found that asking for detail helped increase the number of detections and length of description."}],"\n",["$","p","54",{"children":"\n"}],["$","figure","55",{"children":["\n        ",["$","video","1",{"controls":true,"children":["\n          ",["$","source","1",{"src":"https://cdn.math.computer/v/kosmos2/fish/sm/detail-scene-rich-vocab.mp4","type":"video/mp4","children":"$undefined"}],"\n          Your browser does not support the video tag.\n        "]}],"\n        ",["$","figcaption","3",{"className":"text-center text-sm text-gray-600 dark:text-gray-400","children":"Video processed with prompt \\"}],"\n      "]}],["$","p","56",{"children":"$undefined"}],"\n",["$","p","58",{"children":"I tried “Find the white fish” which did help keep track of the fish a bit, too."}],"\n",["$","h3","60",{"children":"Observations:"}],"\n",["$","ul","62",{"children":["\n",["$","li","1",{"children":"The burrowing behavior was not recognized."}],"\n",["$","li","3",{"children":"Temporal stability of scene descriptions was surprisingly good at first glance."}],"\n",["$","li","5",{"children":["Processing more than a handful of frames per second on my GPU hardware is not possible. If I want real-time annotations, it will require ",["$","em","1",{"children":"a lot"}]," of parallel compute."]}],"\n"]}],"\n",["$","p","64",{"children":"Overall, this was an interesting initial set of experiments.\nI’ll continue to iterate with this model - I think it has potential for some interesting visuals."}],"\n",["$","p","66",{"children":["My iteration cycle needs to be short so that I can stay in a “flow state” when making art, and right now processing images with Kosmos-2 is ",["$","em","1",{"children":"much too slow"}]," for anything pertaining to video."]}],"\n",["$","p","68",{"children":"So while it did detract from playing with the model in more artistic ways, I built and published an API version of the model, which will be required to scale my experiments.\nCan I achieve something approaching real-time processing on a budget?"}],"\n",["$","p","70",{"children":"More on that soon."}],"\n"]}],["$","div",null,{"className":"grid grid-cols-1 md:grid-cols-2 gap-4","children":[["$","figure","0",{"className":"flex flex-col items-center","children":[["$","div",null,{"className":"relative overflow-hidden","children":["$","$Ld",null,{"src":"https://cdn.math.computer/v/kosmos2/fish/sm/frame_000001.png","alt":"Annotated Frame 1","width":960,"height":540,"className":"w-max-full","sizes":"960px","quality":78,"priority":true,"loading":"eager","placeholder":"blur","blurDataURL":"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjcwMCIgaGVpZ2h0PSI0NzUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgPGRlZnM+CiAgICA8bGluZWFyR3JhZGllbnQgaWQ9ImciPgogICAgICA8c3RvcCBzdG9wLWNvbG9yPSIjMDAwMCIgb2Zmc2V0PSIyMCUiIC8+CiAgICAgIDxzdG9wIHN0b3AtY29sb3I9IiMwMDAxIiBvZmZzZXQ9IjUwJSIgLz4KICAgICAgPHN0b3Agc3RvcC1jb2xvcj0iIzAwMDAiIG9mZnNldD0iNzAlIiAvPgogICAgPC9saW5lYXJHcmFkaWVudD4KICA8L2RlZnM+CiAgPHJlY3Qgd2lkdGg9IjcwMCIgaGVpZ2h0PSI0NzUiIGZpbGw9IiMwMDAwIiAvPgogIDxyZWN0IGlkPSJyIiB3aWR0aD0iNzAwIiBoZWlnaHQ9IjQ3NSIgZmlsbD0idXJsKCNnKSIgLz4KICA8YW5pbWF0ZSB4bGluazpocmVmPSIjciIgYXR0cmlidXRlTmFtZT0ieCIgZnJvbT0iLTcwMCIgdG89IjcwMCIgZHVyPSIxcyIgcmVwZWF0Q291bnQ9ImluZGVmaW5pdGUiICAvPgo8L3N2Zz4="}]}],["$","figcaption",null,{"className":"mt-2 text-center text-sm text-gray-600 dark:text-gray-400","dangerouslySetInnerHTML":{"__html":"Kosmos-2 result for frame 1"}}]]}],["$","figure","1",{"className":"flex flex-col items-center","children":[["$","div",null,{"className":"relative overflow-hidden","children":["$","$Ld",null,{"src":"https://cdn.math.computer/v/kosmos2/fish/sm/frame_000010.png","alt":"Annotated Frame 10","width":960,"height":540,"className":"w-max-full","sizes":"960px","quality":78,"priority":false,"loading":"lazy","placeholder":"blur","blurDataURL":"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjcwMCIgaGVpZ2h0PSI0NzUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgPGRlZnM+CiAgICA8bGluZWFyR3JhZGllbnQgaWQ9ImciPgogICAgICA8c3RvcCBzdG9wLWNvbG9yPSIjMDAwMCIgb2Zmc2V0PSIyMCUiIC8+CiAgICAgIDxzdG9wIHN0b3AtY29sb3I9IiMwMDAxIiBvZmZzZXQ9IjUwJSIgLz4KICAgICAgPHN0b3Agc3RvcC1jb2xvcj0iIzAwMDAiIG9mZnNldD0iNzAlIiAvPgogICAgPC9saW5lYXJHcmFkaWVudD4KICA8L2RlZnM+CiAgPHJlY3Qgd2lkdGg9IjcwMCIgaGVpZ2h0PSI0NzUiIGZpbGw9IiMwMDAwIiAvPgogIDxyZWN0IGlkPSJyIiB3aWR0aD0iNzAwIiBoZWlnaHQ9IjQ3NSIgZmlsbD0idXJsKCNnKSIgLz4KICA8YW5pbWF0ZSB4bGluazpocmVmPSIjciIgYXR0cmlidXRlTmFtZT0ieCIgZnJvbT0iLTcwMCIgdG89IjcwMCIgZHVyPSIxcyIgcmVwZWF0Q291bnQ9ImluZGVmaW5pdGUiICAvPgo8L3N2Zz4="}]}],["$","figcaption",null,{"className":"mt-2 text-center text-sm text-gray-600 dark:text-gray-400","dangerouslySetInnerHTML":{"__html":"Kosmos-2 result for frame 10"}}]]}],["$","figure","2",{"className":"flex flex-col items-center","children":[["$","div",null,{"className":"relative overflow-hidden","children":["$","$Ld",null,{"src":"https://cdn.math.computer/v/kosmos2/fish/sm/frame_000100.png","alt":"Annotated Frame 100","width":960,"height":540,"className":"w-max-full","sizes":"960px","quality":78,"priority":false,"loading":"lazy","placeholder":"blur","blurDataURL":"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjcwMCIgaGVpZ2h0PSI0NzUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgPGRlZnM+CiAgICA8bGluZWFyR3JhZGllbnQgaWQ9ImciPgogICAgICA8c3RvcCBzdG9wLWNvbG9yPSIjMDAwMCIgb2Zmc2V0PSIyMCUiIC8+CiAgICAgIDxzdG9wIHN0b3AtY29sb3I9IiMwMDAxIiBvZmZzZXQ9IjUwJSIgLz4KICAgICAgPHN0b3Agc3RvcC1jb2xvcj0iIzAwMDAiIG9mZnNldD0iNzAlIiAvPgogICAgPC9saW5lYXJHcmFkaWVudD4KICA8L2RlZnM+CiAgPHJlY3Qgd2lkdGg9IjcwMCIgaGVpZ2h0PSI0NzUiIGZpbGw9IiMwMDAwIiAvPgogIDxyZWN0IGlkPSJyIiB3aWR0aD0iNzAwIiBoZWlnaHQ9IjQ3NSIgZmlsbD0idXJsKCNnKSIgLz4KICA8YW5pbWF0ZSB4bGluazpocmVmPSIjciIgYXR0cmlidXRlTmFtZT0ieCIgZnJvbT0iLTcwMCIgdG89IjcwMCIgZHVyPSIxcyIgcmVwZWF0Q291bnQ9ImluZGVmaW5pdGUiICAvPgo8L3N2Zz4="}]}],["$","figcaption",null,{"className":"mt-2 text-center text-sm text-gray-600 dark:text-gray-400","dangerouslySetInnerHTML":{"__html":"Kosmos-2 result for frame 100"}}]]}],["$","figure","3",{"className":"flex flex-col items-center","children":[["$","div",null,{"className":"relative overflow-hidden","children":["$","$Ld",null,{"src":"https://cdn.math.computer/v/kosmos2/fish/sm/frame_001000.png","alt":"Annotated Frame 1000","width":960,"height":540,"className":"w-max-full","sizes":"960px","quality":78,"priority":false,"loading":"lazy","placeholder":"blur","blurDataURL":"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjcwMCIgaGVpZ2h0PSI0NzUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgPGRlZnM+CiAgICA8bGluZWFyR3JhZGllbnQgaWQ9ImciPgogICAgICA8c3RvcCBzdG9wLWNvbG9yPSIjMDAwMCIgb2Zmc2V0PSIyMCUiIC8+CiAgICAgIDxzdG9wIHN0b3AtY29sb3I9IiMwMDAxIiBvZmZzZXQ9IjUwJSIgLz4KICAgICAgPHN0b3Agc3RvcC1jb2xvcj0iIzAwMDAiIG9mZnNldD0iNzAlIiAvPgogICAgPC9saW5lYXJHcmFkaWVudD4KICA8L2RlZnM+CiAgPHJlY3Qgd2lkdGg9IjcwMCIgaGVpZ2h0PSI0NzUiIGZpbGw9IiMwMDAwIiAvPgogIDxyZWN0IGlkPSJyIiB3aWR0aD0iNzAwIiBoZWlnaHQ9IjQ3NSIgZmlsbD0idXJsKCNnKSIgLz4KICA8YW5pbWF0ZSB4bGluazpocmVmPSIjciIgYXR0cmlidXRlTmFtZT0ieCIgZnJvbT0iLTcwMCIgdG89IjcwMCIgZHVyPSIxcyIgcmVwZWF0Q291bnQ9ImluZGVmaW5pdGUiICAvPgo8L3N2Zz4="}]}],["$","figcaption",null,{"className":"mt-2 text-center text-sm text-gray-600 dark:text-gray-400","dangerouslySetInnerHTML":{"__html":"Kosmos-2 result for frame 1000"}}]]}]]}]]}]}]}],["$","nav",null,{"className":"flex justify-between w-full mt-8 mb-4 text-3xl font-bold text-gray-600 dark:text-gray-400 px-4","children":[["$","div",null,{"className":"flex-1 flex justify-start","children":null}],["$","div",null,{"className":"flex-1 flex justify-end","children":["$","$Lb",null,{"href":"/1/2","className":"hover:underline","children":"→"}]}]]}]]}]
a:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"MathematicalMichaelx2025"}],["$","meta","3",{"name":"description","content":"Digital Art Log for Dr. Michael Pilosov"}],["$","link","4",{"rel":"icon","href":"/2025/favicon.ico","type":"image/x-icon","sizes":"48x48"}]]
1:null
